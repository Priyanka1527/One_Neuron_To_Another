{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Iris data set :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title of the data set: Iris Plants Database\n",
    "\n",
    "#### Number of instance: 150\n",
    "\n",
    "#### Number of attributes : 5 (4 predictive, 1 name)\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "   5. **Class:** Species of the flower\n",
    "              - Iris Setosa\n",
    "              - Iris Versicolour\n",
    "              - Iris Virginica  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/iris.data', sep=',', header=None, names=['SepalLengthCm','SepalWidthCm',\n",
    "                                                                   'PetalLengthCm','PetalWidthCm','Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare the input data\n",
    "X = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "X = np.array(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using one-hot-encoding technique to map the categorical value of species to numerical i.e. \n",
    "#(Iris-setosa, Iris-versicolor, Iris-virginica) to (0,1,2) and then to one-hot encoded \n",
    "#([1, 0, 0], [0, 1, 0], [0, 0, 1])\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "Y = df.Species\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set into train/validation/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network consists of the following components:\n",
    "        - An input layer, x\n",
    "        - Arbitary number of hidden layers\n",
    "        - An out put layer, y\n",
    "        - A set of weights and biases between each layer, W and b\n",
    "        - A choice of activation function for each hidden layer, Ïƒ (Sigmoid activation function used here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights and biases !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How it works ?\n",
    "        - The weights of the network are initialized randomly in the range [-1,1]\n",
    "        \n",
    "        - The bias has a constant value of 1\n",
    "        \n",
    "        - The function takes nodes as input which is basically a list of integers denoting the number of nodes in \n",
    "        each layer and length of the list denotes the number of layers\n",
    "        \n",
    "        - The function returns a multi-dimensional array as output which corresnpond to the weights\n",
    "        \n",
    "        - Each element in the weights list represents a hidden layer and has the weights of connections from the \n",
    "        previous layer (including the bias) to the current layer.\n",
    "        \n",
    "        \n",
    "        \n",
    "The right values for the weights and biases determines the strength of the predictions. The process of fine-tuning the weights and biases from the input data is known as training the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeWeight(nodes):\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        wt = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)] for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(wt))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main function !!\n",
    "\n",
    "#### How it works ?\n",
    "\n",
    "    - This function actually trains the network for given number of iterations. The input parameters are:\n",
    "        - training data and target values\n",
    "        - validation data and target values\n",
    "        - number of iterations , default=10\n",
    "        - list of integers\n",
    "        - learning rate of back-propagation algorithm, default=0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNet(X_train, Y_train, X_val=None, Y_val=None, iterations=10, nodes=[], rate=0.15):\n",
    "    hiddenLayers = len(nodes) - 1\n",
    "    weights = initializeWeight(nodes)\n",
    "\n",
    "    for iteration in range(1, iterations+1):\n",
    "        weights = trainNetwork(X_train, Y_train, rate, weights)\n",
    "\n",
    "        #Print the accuracy of training and validation after every 20 iterations\n",
    "        if(iteration % 20 == 0):\n",
    "            print(\"Iteration {}\".format(iteration))\n",
    "            print(\"Training Accuracy:{}\".format(accuracy(X_train, Y_train, weights)))\n",
    "            if X_val.any():\n",
    "                print(\"Validation Accuracy:{}\".format(accuracy(X_val, Y_val, weights)))\n",
    "                        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights need to be continuously adjusted across each iteration to increase the accuracy of the network. In each iteration the network is trained using forward/backward propagation algorithm. First, the input is passed through the network and output is calculated and then, according to the error of output, the weights are updated backwards. So basically, the error is propagated backward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation !!\n",
    "\n",
    "    - Each layer receives an input and computes the output which is calculated by passing the dot product of input and weights of the layer to a activation function(Sigmiod in this case).\n",
    "    \n",
    "    - The output of each layer is the input for the next layer\n",
    "    \n",
    "    - The input of the first layer is feature vector and output of last layer is the prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(x, weights, layers):\n",
    "    output, current_input = [x], x\n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(current_input, weights[j].T))\n",
    "        output.append(activation)\n",
    "        current_input = np.append(1, activation) # add the bias = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation !!\n",
    "\n",
    "    - Calculate the error rate of the final output\n",
    "    \n",
    "    - Propagate the error backwards and adjusts the weights\n",
    "        - Delta is calculated as : error of next layer times sigmoid derivation of the current layer output\n",
    "        \n",
    "        - Weights between current and previous layer are updated as: multiple Delta with the putput of previous \n",
    "        layer and rate, then add this to the weight of previous layer\n",
    "        \n",
    "        - calculate error of the current layer, rmeove the bias form the weights of the previous layer and \n",
    "        then multipy this result with Delta to get error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(y, output, weights, layers):\n",
    "    outputFinal = output[-1]\n",
    "    error = np.matrix(y - outputFinal) #Calculate the error at last output\n",
    "    \n",
    "    #Back propagate the error\n",
    "    for j in range(layers, 0, -1):\n",
    "        currOutput = output[j]\n",
    "        \n",
    "        if(j > 1):\n",
    "            # Add previous output\n",
    "            prevOutput = np.append(1, output[j-1])\n",
    "        else:\n",
    "            prevOutput = output[0]\n",
    "        \n",
    "        delta = np.multiply(error, sigmoidDerivative(currOutput))\n",
    "        weights[j-1] += rate * np.multiply(delta.T, prevOutput)\n",
    "\n",
    "        wt = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
    "        error = np.dot(delta, wt) # Calculate error for current layer\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Prediction functions !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will perform forward and backward propagation, the new weights will be returned n the end\n",
    "def trainNetwork(X, Y, rate, weights):\n",
    "    layers = len(weights)\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], Y[i]\n",
    "        x = np.matrix(np.append(1, x)) # Add feature vector\n",
    "        \n",
    "        output = feedForward(x, weights, layers)\n",
    "        weights = backPropagation(y, output, weights, layers)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function !!\n",
    "\n",
    "    - Activation function of a node defines the output of that node, or \"neuron,\" given an input or set of inputs \n",
    "    \n",
    "    - This output is then used as input for the next node and so on until a desired solution to the original \n",
    "    problem is found\n",
    "    \n",
    "    - It maps the resulting values into the desired range such as between 0 to 1 or -1 to 1 etc.\n",
    "    \n",
    "    - Activation function gets to decide which neurons will push forward the values into the next layer\n",
    "    \n",
    "    - Sigmoid activation function has been used in this assignment.\n",
    "     It takes a value as input and outputs another value between 0 and 1. It is non-linear and easy to work \n",
    "     with when constructing a neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the prediction work ?\n",
    "\n",
    "    - The input is first passed to the network\n",
    "    - The output will be array of three real numbers corresponding to the three species\n",
    "    - The higher value of a number indicates the most probable class\n",
    "    - findMaxActivation() will find the maximum valued output and then corresponding index is set to 1\n",
    "    - So, the predicted class is the one that the network is most confident of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item)\n",
    "    \n",
    "    #forward propagation\n",
    "    output = feedForward(item, weights, layers)\n",
    "    \n",
    "    outputFinal = output[-1].A1\n",
    "    index = findMaxActivation(outputFinal)\n",
    "\n",
    "    y = [0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxActivation(output):\n",
    "    m, index = output[0], 0\n",
    "    for i in range(1, len(output)):\n",
    "        if(output[i] > m):\n",
    "            m, index = output[i], i\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy of prediction !!\n",
    "\n",
    "    - given the computed weights, the model predicts the class of each object in its input\n",
    "    - predicted class is checked against the actual class\n",
    "    - increase the number of correct classfication if it matches\n",
    "    - percentage of correct predictions is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, weights):\n",
    "    correct_classification = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        prediction = predict(x, weights)\n",
    "\n",
    "        if(y == prediction):\n",
    "            correct_classification += 1\n",
    "\n",
    "    return correct_classification / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20\n",
      "Training Accuracy:0.8947368421052632\n",
      "Validation Accuracy:0.9230769230769231\n",
      "Iteration 40\n",
      "Training Accuracy:0.8859649122807017\n",
      "Validation Accuracy:0.9230769230769231\n",
      "Iteration 60\n",
      "Training Accuracy:0.8508771929824561\n",
      "Validation Accuracy:0.9230769230769231\n",
      "Iteration 80\n",
      "Training Accuracy:0.8508771929824561\n",
      "Validation Accuracy:0.9230769230769231\n",
      "Iteration 100\n",
      "Training Accuracy:0.9736842105263158\n",
      "Validation Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "# Run it here\n",
    "features = len(X[0]) # Number of features - using all of them\n",
    "classes = len(Y[0]) # Number of classes\n",
    "\n",
    "layers = [features, 5, 10, classes]\n",
    "rate, iterations = 0.15, 100\n",
    "\n",
    "weights = neuralNet(X_train, Y_train, X_val, Y_val, iterations=iterations, nodes=layers, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "#Final testing accuracy\n",
    "print(\"Testing Accuracy: {}\".format(accuracy(X_test, Y_test, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check an example prediction !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.4 3.1 5.5 1.8] [0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0], list(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predict(X_test[0], weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicts the same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: \n",
    "#https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6\n",
    "#https://towardsdatascience.com/neural-network-on-iris-data-4e99601a42c8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
